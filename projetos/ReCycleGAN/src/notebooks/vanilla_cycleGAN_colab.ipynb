{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMh5APzXGI0j"
      },
      "source": [
        "# Implementing the CycleGAN (vanilla architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVYYbaJRGCWv"
      },
      "source": [
        "## Objetivo\n",
        "\n",
        "Reproduzir uma CycleGAN vanilla, baseada no artigo [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593v7).\n",
        "\n",
        "Mais especificamente, construir, treinar e documentar esta arquitetura de GAN utilizando Pytorch, baseado na implementação em [https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJMp16f2XPWB",
        "outputId": "0429428f-a9dd-4d6e-a288-792a1b132435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU wandb pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l19iQGjKGDOw",
        "outputId": "8ecc1648-e54a-4294-ee63-d660f9a85ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0)\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "current_dir = Path.cwd()\n",
        "sys.path.append(str(current_dir))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from drive.MyDrive.CycleGAN.src.utils.data_loader import get_img_dataloader  # pylint: disable=all\n",
        "from drive.MyDrive.CycleGAN.src.utils import show_img  # pylint: disable=all\n",
        "from drive.MyDrive.CycleGAN.src.models.basemodel import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2rPtCzrXql6"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\" : 8,\n",
        "    \"n_features\" : 64, #64\n",
        "    \"n_residual_blocks\": 9, #9\n",
        "    \"n_downsampling\": 2, #2\n",
        "\n",
        "    \"cycle_loss_weight\":10, #10\n",
        "    \"id_loss_weight\":5, #5\n",
        "\n",
        "    \"num_epochs\" : 100,\n",
        "    \"device\" : torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\"),\n",
        "\n",
        "    \"lr\" : 0.0002, #0.0002\n",
        "    \"beta1\" : 0.5,  #0.5\n",
        "    \"beta2\" : 0.999, #0.999\n",
        "\n",
        "    \"channels\" : 3, #3\n",
        "    \"checkpoint_interval\" : 2,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqRjmsWHPA5X"
      },
      "source": [
        "# CycleGAN Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhjn4Wjv45-K"
      },
      "source": [
        "## CycleGAN generator\n",
        "\n",
        "Each CycleGAN generator has three sections\n",
        "\n",
        "- Encoder\n",
        "- Transformer\n",
        "- Decoder\n",
        "\n",
        "The input image is passed into the encoder. The encoder extracts features from the input image by using Convolutions and compressed the representation of image but increase the number of channels.\n",
        "\n",
        "The encoder consists of 3 convolution that reduces the representation by 1/4 th of actual image size. Consider an image of size (256, 256, 3) which we input into the encoder, the output of encoder will be (64, 64, 256).\n",
        "\n",
        "Then the output of encoder after activation function is applied is passed into the transformer. The transformer contains 6 or 9 residual blocks based on the size of input.\n",
        "\n",
        "The output of transformer is then passed into the decoder which uses 2 -deconvolution block of fraction strides to increase the size of representation to original size.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "The architecture of generator is:\n",
        "\n",
        "`c7s1-64, d128, d256, R256, R256, R256,\n",
        "R256, R256, R256, u128, u64, c7s1-3\n",
        "\n",
        "where c7s1-k denote a 7×7 Convolution-InstanceNorm-ReLU layer with k filters and stride 1. dk denotes a 3 × 3 Convolution-InstanceNorm-ReLU layer with k filters and stride 2. Rk denotes a residual block that contains two 3 × 3 convolution layers with the same number of filters on both layer. uk denotes a 3 × 3 fractional-strides-Convolution-InstanceNorm-ReLU layer with k filters and stride 1/2 (i.e deconvolution operation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alxDPbhV17qf"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual block.\n",
        "\n",
        "    Args:\n",
        "    - in_features: Number of features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "\n",
        "        conv_block = [\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features)\n",
        "        ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the residual block.\"\"\"\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Generator network.\n",
        "\n",
        "    Args:\n",
        "    - input_nc: Number of input channels.\n",
        "    - output_nc: Number of output channels.\n",
        "    - n_residual_blocks: Number of residual blocks. Default is 9.\n",
        "    - n_features: Number of features. Default is 64.\n",
        "    - n_downsampling: Number of downsampling layers. Default is 2.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9, n_features=64, n_downsampling=2):\n",
        "        super().__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, n_features, 7),\n",
        "            nn.InstanceNorm2d(n_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "\n",
        "        for i in range(n_downsampling):\n",
        "            n_feat = n_features * 2 ** i\n",
        "            model += [\n",
        "                nn.Conv2d(n_feat, 2 * n_feat, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(2 * n_feat),\n",
        "            ]\n",
        "\n",
        "        n_feat = n_features * 2 ** n_downsampling\n",
        "        for i in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(n_feat)]\n",
        "\n",
        "        for i in range(n_downsampling):\n",
        "            n_feat = n_features * 2 ** (n_downsampling - i)\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(n_feat, n_feat // 2, 3,\n",
        "                                   stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(n_feat // 2),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(n_features, output_nc, 7)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the generator.\"\"\"\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhfSKwtOpIsN",
        "outputId": "b2edbdfd-dbf0-4a0e-fe22-7dbaf50e86e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator instantiation and basic tests passed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate generators\n",
        "gen_AtoB = Generator(3, 3)\n",
        "gen_BtoA = Generator(3, 3)\n",
        "\n",
        "# Basic tests with random input\n",
        "input_tensor = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "output_tensor = gen_AtoB(input_tensor)\n",
        "assert output_tensor.shape == (1, 3, 256, 256), \"Generator output has incorrect shape\"\n",
        "\n",
        "output_tensor = gen_BtoA(input_tensor)\n",
        "assert output_tensor.shape == (1, 3, 256, 256), \"Generator output has incorrect shape\"\n",
        "\n",
        "\n",
        "print(\"Generator instantiation and basic tests passed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8_IFKeJExbl"
      },
      "source": [
        "## CycleGAN Discriminator\n",
        "\n",
        "In discriminator the authors use PatchGAN discriminator. The difference between a PatchGAN and regular GAN discriminator is that rather the regular GAN maps from a 256×256 image to a single scalar output, which signifies “real” or “fake”, whereas the PatchGAN maps from 256×256 to an NxN (here 70×70) array of outputs X, where each Xij signifies whether the patch ij in the image is real or fake.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "The architecture of discriminator is :\n",
        "\n",
        "`C64-C128-C256-C512`\n",
        "\n",
        "where Ck is 4×4 convolution-InstanceNorm-LeakyReLU layer with k filters and stride 2. We don’t apply InstanceNorm on the first layer (C64). After the last layer, we apply convolution operation to produce a 1×1 output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg1GyEAe18kQ"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminator network.\n",
        "\n",
        "    Args:\n",
        "    - input_nc: Number of input channels.\n",
        "    - n_features: Number of features. Default is 64.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc, n_features=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_nc, n_features, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            self.discriminator_block(n_features, 2 * n_features),\n",
        "            self.discriminator_block(2 * n_features, 4 * n_features),\n",
        "            self.discriminator_block(4 * n_features, 8 * n_features),\n",
        "\n",
        "            nn.Conv2d(8 * n_features, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def discriminator_block(self, input_dim, output_dim):\n",
        "        \"\"\"\n",
        "        Returns downsampling layers of each discriminator block\n",
        "\n",
        "        Args:\n",
        "        - input_dim: Number of input channels.\n",
        "        - output_dim: Number of output channels.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(input_dim, output_dim, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(output_dim),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the discriminator.\"\"\"\n",
        "        x =  self.model(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        return x.view(x.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y0gm7fLqcZY",
        "outputId": "4ca87994-2029-4eb7-a135-ebfefe29612f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discriminator instantiation and basic tests passed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate discriminators\n",
        "dis_A = Discriminator(3, 1)\n",
        "dis_B = Discriminator(3, 1)\n",
        "\n",
        "# Basic tests with random input\n",
        "input_tensor = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "output_tensor = dis_A(input_tensor)\n",
        "assert output_tensor.shape == (1, 1), \"Discriminator output has incorrect shape\"\n",
        "\n",
        "output_tensor = dis_B(input_tensor)\n",
        "assert output_tensor.shape == (1, 1), \"Discriminator output has incorrect shape\"\n",
        "\n",
        "print(\"Discriminator instantiation and basic tests passed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fseKuKXBjrLP"
      },
      "source": [
        "## Cost Functions\n",
        "\n",
        "- **Adversarial Loss:**  We apply adversarial loss to both our mappings of generators and discriminators. This adversary loss is written as :\n",
        "\n",
        "$$ Loss_{advers} \\left ( G, D_y, X, Y \\right ) =\\frac{1}{m}\\sum \\left ( 1 - D_y\\left ( G\\left ( x \\right ) \\right ) \\right )^{2} $$  \n",
        "\n",
        "$$ Loss_{advers}\\left ( F, D_x, Y, X \\right ) =\\frac{1}{m}\\sum \\left ( 1 - D_x\\left ( F\\left ( y \\right ) \\right ) \\right )^{2} $$   \n",
        "\n",
        "- **Cycle Consistency Loss:** Given a random set of images adversarial network can map the set of input image to random permutation of images in the output domain which may induce the output distribution similar to target distribution. Thus adversarial mapping cannot guarantee the input xi  to yi . For this to happen the author proposed that process should be cycle-consistent.\n",
        "\n",
        "  This loss function used in Cycle GAN to measure the error rate of  inverse mapping G(x) -> F(G(x)). The behavior induced by this loss function cause closely matching the real input (x) and F(G(x))\n",
        "\n",
        "$$ Loss_{cyc}\\left ( G, F, X, Y \\right ) =\\frac{1}{m}\\left [ \\left ( F\\left ( G\\left ( x_i \\right ) \\right )-x_i \\right ) +\\left ( G\\left ( F\\left ( y_i \\right ) \\right )-y_i \\right ) \\right ] $$   \n",
        "\n",
        "\n",
        "The Cost function we used is the sum of adversarial loss and cyclic consistent loss:\n",
        "\n",
        "\n",
        "$$ L\\left ( G, F, D_x, D_y \\right ) = L_{advers}\\left (G, D_y, X, Y \\right ) + L_{advers}\\left (F, D_x, Y, X \\right ) + \\lambda L_{cycl}\\left ( G, F, X, Y \\right ) $$\n",
        "\n",
        "and our aim is :\n",
        "\n",
        "\n",
        "$$ arg \\underset{G, F}{min}\\underset{D_x, D_y}{max}L\\left ( G, F, D_x, D_y \\right ) $$   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDJzHyDbCnsW"
      },
      "outputs": [],
      "source": [
        "class CycleGANLoss(nn.Module):\n",
        "    \"\"\"Define different GAN objectives.\n",
        "\n",
        "    The CycleGANLoss class abstracts away the need to create the target label tensor\n",
        "    that has the same size as the input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_real_label=1.0, target_fake_label=0.0):\n",
        "        super(CycleGANLoss, self).__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _get_target_tensor(self, prediction, target_is_real):\n",
        "        \"\"\"Create label tensors with the same size as the input.\n",
        "\n",
        "        Parameters:\n",
        "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
        "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
        "\n",
        "        Returns:\n",
        "            A label tensor filled with ground truth label, and with the size of the input\n",
        "        \"\"\"\n",
        "\n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
        "\n",
        "        Parameters:\n",
        "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
        "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
        "\n",
        "        Returns:\n",
        "            the calculated loss.\n",
        "        \"\"\"\n",
        "        target_tensor = self._get_target_tensor(prediction, target_is_real)\n",
        "        loss = self.loss(prediction, target_tensor)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ERKSpR0EiLM",
        "outputId": "f9c16824-0bab-4ced-8b07-ccefbcc0e711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizers, loss functions, and assert tests instantiated successfully.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate optimizers\n",
        "optimizer_G = optim.Adam(list(gen_AtoB.parameters()) + list(gen_BtoA.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_A = optim.Adam(dis_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_B = optim.Adam(dis_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Instantiate loss functions\n",
        "criterionGAN = CycleGANLoss()\n",
        "criterionCycle = torch.nn.L1Loss()\n",
        "\n",
        "# Assert tests for dimensions, forward and backward pass, and test the losses calculations\n",
        "# Test generator forward pass\n",
        "input_tensor = torch.randn(1, 3, 256, 256)\n",
        "output_tensor = gen_AtoB(input_tensor)\n",
        "assert output_tensor.shape == (1, 3, 256, 256)\n",
        "\n",
        "# Test discriminator forward pass\n",
        "output_tensor = dis_A(input_tensor)\n",
        "assert output_tensor.shape == (1, 1)\n",
        "\n",
        "# Test backward pass for generator\n",
        "output_tensor = gen_AtoB(input_tensor)\n",
        "loss = criterionGAN(output_tensor, True)\n",
        "loss.backward()\n",
        "\n",
        "# Test backward pass for discriminator\n",
        "output_tensor = dis_A(input_tensor)\n",
        "loss = criterionGAN(output_tensor, True)\n",
        "loss.backward()\n",
        "\n",
        "# Test cycle consistency loss\n",
        "fake_B = gen_AtoB(input_tensor)\n",
        "rec_A = gen_BtoA(fake_B)\n",
        "cycle_loss = criterionCycle(rec_A, input_tensor)\n",
        "assert cycle_loss.shape == ()\n",
        "\n",
        "# Test GAN loss\n",
        "fake_B = gen_AtoB(input_tensor)\n",
        "pred_fake = dis_B(fake_B)\n",
        "gan_loss = criterionGAN(pred_fake, True)\n",
        "assert gan_loss.shape == ()\n",
        "\n",
        "print(\"Optimizers, loss functions, and assert tests instantiated successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2HXykujXVF2"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnCb2XkFRMwQ",
        "outputId": "f3e91172-0b8a-4601-d2e0-70678d1f903a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CycleGAN/nexet\n"
          ]
        }
      ],
      "source": [
        "folder = Path().resolve() / 'drive' / 'MyDrive' / 'CycleGAN' / 'nexet'\n",
        "print(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWmVGr01-AR-",
        "outputId": "959441bb-9edf-4ed2-e1c4-2a83eee4ca75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train A CSV: /content/drive/MyDrive/CycleGAN/nexet/input_A_train.csv\n",
            "Train B CSV: /content/drive/MyDrive/CycleGAN/nexet/input_B_train.csv\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "folder = Path().resolve() / 'drive' / 'MyDrive' / 'CycleGAN' / 'nexet'\n",
        "train_A_csv = folder / 'input_A_train.csv'\n",
        "test_A_csv = folder / 'input_A_test.csv'\n",
        "train_B_csv = folder / 'input_B_train.csv'\n",
        "test_B_csv = folder / 'input_B_test.csv'\n",
        "\n",
        "print(f\"Train A CSV: {train_A_csv}\")\n",
        "print(f\"Train B CSV: {train_B_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEpKsZtqIlHX",
        "outputId": "82fbe08b-dae3-4818-ebb0-37d1b6cff2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 3524\n",
            "Number of test samples: 882\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transformation = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "batch_size = hyperparameters[\"batch_size\"]\n",
        "train_A = get_img_dataloader(csv_file=train_A_csv, batch_size=batch_size, transformation=transformation)\n",
        "test_A = get_img_dataloader(csv_file=test_A_csv, batch_size=batch_size, transformation=transformation)\n",
        "train_B = get_img_dataloader(csv_file=train_B_csv, batch_size=batch_size, transformation=transformation)\n",
        "test_B = get_img_dataloader(csv_file=test_B_csv, batch_size=batch_size, transformation=transformation)\n",
        "\n",
        "n_train = min(len(train_A.dataset), len(train_B.dataset))\n",
        "train_A.dataset.set_len(n_train)\n",
        "train_B.dataset.set_len(n_train)\n",
        "print(f\"Number of training samples: {n_train}\")\n",
        "\n",
        "n_test = min(len(test_A.dataset), len(test_B.dataset))\n",
        "test_A.dataset.set_len(n_test)\n",
        "test_B.dataset.set_len(n_test)\n",
        "print(f\"Number of test samples: {n_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvi9CtzbhXd"
      },
      "source": [
        "# Main class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVGrL6ojPA5d"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Loss:\n",
        "    \"\"\"Dataclass for CycleGAN losses.\"\"\"\n",
        "    loss_G: torch.Tensor\n",
        "    loss_D_A: torch.Tensor\n",
        "    loss_D_B: torch.Tensor\n",
        "    loss_G_ad: torch.Tensor\n",
        "    loss_G_cycle: torch.Tensor\n",
        "    loss_G_id: torch.Tensor\n",
        "\n",
        "class CycleGAN(BaseModel):\n",
        "    \"\"\"\n",
        "    CycleGAN model for image-to-image translation.\n",
        "\n",
        "    Args:\n",
        "    - input_nc: Number of input channels. Default is 3.\n",
        "    - output_nc: Number of output channels. Default is 3.\n",
        "    - n_residual_blocks: Number of residual blocks in generators. Default is 9.\n",
        "    - n_features: Number of features in generators and discriminators. Default is 64.\n",
        "    - n_downsampling: Number of downsampling layers in generators. Default is 2.\n",
        "    - cycle_loss_weight: Weight for cycle-consistency loss. Default is 10.\n",
        "    - id_loss_weight: Weight for identity loss. Default is 5.\n",
        "    - lr: Learning rate. Default is 0.0002.\n",
        "    - beta1: Beta1 for Adam optimizer. Default is 0.5.\n",
        "    - beta2: Beta2 for Adam optimizer. Default is 0.999.\n",
        "    - device: 'cuda' or 'cpu'. Default is 'cpu'.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc=3, output_nc=3,\n",
        "                 n_residual_blocks=9, n_features=64, n_downsampling=2,\n",
        "                 cycle_loss_weight=10, id_loss_weight=5,\n",
        "                 lr=0.0002, beta1=0.5, beta2=0.999, device='cpu'):\n",
        "        super().__init__(device)\n",
        "\n",
        "        # Initialize generators and discriminators\n",
        "        gen_params = {\n",
        "            'input_nc': input_nc,\n",
        "            'output_nc': output_nc,\n",
        "            'n_residual_blocks': n_residual_blocks,\n",
        "            'n_features': n_features,\n",
        "            'n_downsampling': n_downsampling\n",
        "        }\n",
        "        self.gen_AtoB = Generator(**gen_params).to(self.device)\n",
        "        self.gen_BtoA = Generator(**gen_params).to(self.device)\n",
        "        self.dis_A = Discriminator(input_nc, n_features=n_features).to(self.device)\n",
        "        self.dis_B = Discriminator(input_nc, n_features=n_features).to(self.device)\n",
        "\n",
        "        # Define losses\n",
        "        self.adversarial_loss = CycleGANLoss().to(self.device)\n",
        "        self.cycle_loss = nn.L1Loss().to(self.device)\n",
        "        self.identity_loss = nn.L1Loss().to(self.device)\n",
        "\n",
        "        # Setup optimizers using the BaseModel's helper function\n",
        "        self.optimizer_G = self.setup_optimizers(\n",
        "            list(self.gen_AtoB.parameters()) + list(self.gen_BtoA.parameters()), lr, beta1, beta2\n",
        "        )\n",
        "        self.optimizer_D_A = self.setup_optimizers(self.dis_A.parameters(), lr, beta1, beta2)\n",
        "        self.optimizer_D_B = self.setup_optimizers(self.dis_B.parameters(), lr, beta1, beta2)\n",
        "\n",
        "        self.device = device\n",
        "        self.cycle_loss_weight = cycle_loss_weight\n",
        "        self.id_loss_weight = id_loss_weight\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"String representation of the CycleGAN model.\"\"\"\n",
        "        return (\n",
        "            f'CycleGAN Model\\n'\n",
        "            f'Generators:\\n'\n",
        "            f'  A to B: {self.gen_AtoB}\\n'\n",
        "            f'  B to A: {self.gen_BtoA}\\n'\n",
        "            f'Discriminators:\\n'\n",
        "            f'  A: {self.dis_A}\\n'\n",
        "            f'  B: {self.dis_B}\\n'\n",
        "            f'Losses:\\n'\n",
        "            f'  Adversarial: {self.adversarial_loss}\\n'\n",
        "            f'  Cycle: {self.cycle_loss}\\n'\n",
        "            f'  Identity: {self.identity_loss}\\n'\n",
        "        )\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"\n",
        "        Set the CycleGAN model and its submodules to evaluation mode.\n",
        "        \"\"\"\n",
        "        self.gen_AtoB.eval()\n",
        "        self.gen_BtoA.eval()\n",
        "        self.dis_A.eval()\n",
        "        self.dis_B.eval()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Set the CycleGAN model and its submodules to training mode.\n",
        "        \"\"\"\n",
        "        self.gen_AtoB.train()\n",
        "        self.gen_BtoA.train()\n",
        "        self.dis_A.train()\n",
        "        self.dis_B.train()\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\"\n",
        "        Get the model state dictionary.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'gen_AtoB': self.gen_AtoB.state_dict(),\n",
        "            'gen_BtoA': self.gen_BtoA.state_dict(),\n",
        "            'dis_A': self.dis_A.state_dict(),\n",
        "            'dis_B': self.dis_B.state_dict(),\n",
        "            'optimizer_G': self.optimizer_G.state_dict(),\n",
        "            'optimizer_D_A': self.optimizer_D_A.state_dict(),\n",
        "            'optimizer_D_B': self.optimizer_D_B.state_dict(),\n",
        "        }\n",
        "\n",
        "\n",
        "    def forward(self, real_A, real_B): # pylint: disable=arguments-differ\n",
        "        \"\"\"\n",
        "        Forward pass for both generators.\n",
        "        \"\"\"\n",
        "        fake_B = self.gen_AtoB(real_A)\n",
        "        fake_A = self.gen_BtoA(real_B)\n",
        "\n",
        "        return fake_B, fake_A\n",
        "\n",
        "    def compute_loss(self, real_A, real_B): # pylint: disable=arguments-differ\n",
        "        \"\"\"\n",
        "        Computes the total loss for generators and discriminators\n",
        "        using CycleGANLoss for adversarial loss.\n",
        "        \"\"\"\n",
        "        fake_B, fake_A = self.forward(real_A, real_B)\n",
        "\n",
        "        # Identity loss\n",
        "        loss_identity_A = self.identity_loss(self.gen_BtoA(real_A), real_A)\n",
        "        loss_identity_B = self.identity_loss(self.gen_AtoB(real_B), real_B)\n",
        "\n",
        "        # GAN loss using CycleGANLoss\n",
        "        loss_G_AtoB = self.adversarial_loss(self.dis_B(fake_B), target_is_real=True)\n",
        "        loss_G_BtoA = self.adversarial_loss(self.dis_A(fake_A), target_is_real=True)\n",
        "\n",
        "        # Cycle-consistency loss\n",
        "        loss_cycle_A = self.cycle_loss(self.gen_BtoA(fake_B), real_A)\n",
        "        loss_cycle_B = self.cycle_loss(self.gen_AtoB(fake_A), real_B)\n",
        "\n",
        "        # Total generator loss\n",
        "        loss_G_ad = loss_G_AtoB + loss_G_BtoA\n",
        "        loss_G_cycle = loss_cycle_A + loss_cycle_B\n",
        "        loss_G_id = loss_identity_A + loss_identity_B\n",
        "        loss_G = loss_G_ad + self.cycle_loss_weight * loss_G_cycle + self.id_loss_weight * loss_G_id\n",
        "\n",
        "        # Discriminator A loss (real vs fake)\n",
        "        loss_real_A = self.adversarial_loss(self.dis_A(real_A), target_is_real=True)\n",
        "        loss_fake_A = self.adversarial_loss(self.dis_A(fake_A.detach()), target_is_real=False)\n",
        "        loss_D_A = (loss_real_A + loss_fake_A) * 0.5\n",
        "\n",
        "        # Discriminator B loss (real vs fake)\n",
        "        loss_real_B = self.adversarial_loss(self.dis_B(real_B), target_is_real=True)\n",
        "        loss_fake_B = self.adversarial_loss(self.dis_B(fake_B.detach()), target_is_real=False)\n",
        "        loss_D_B = (loss_real_B + loss_fake_B) * 0.5\n",
        "\n",
        "        return Loss(\n",
        "            loss_G=loss_G,\n",
        "            loss_D_A=loss_D_A,\n",
        "            loss_D_B=loss_D_B,\n",
        "            loss_G_ad=loss_G_ad.detach(),\n",
        "            loss_G_cycle=loss_G_cycle.detach(),\n",
        "            loss_G_id=loss_G_id.detach()\n",
        "        )\n",
        "\n",
        "    def optimize(self, real_A, real_B): # pylint: disable=arguments-differ\n",
        "        \"\"\"\n",
        "        Perform one optimization step for the generators and discriminators.\n",
        "        \"\"\"\n",
        "        self.train()\n",
        "        loss = self.compute_loss(real_A, real_B)\n",
        "\n",
        "        # Optimize Generators\n",
        "        self.optimizer_G.zero_grad()\n",
        "        loss.loss_G.backward()\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "        # Optimize Discriminator A\n",
        "        self.optimizer_D_A.zero_grad()\n",
        "        loss.loss_D_A.backward()\n",
        "        self.optimizer_D_A.step()\n",
        "\n",
        "        # Optimize Discriminator B\n",
        "        self.optimizer_D_B.zero_grad()\n",
        "        loss.loss_D_B.backward()\n",
        "        self.optimizer_D_B.step()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def save_model(self, path='cycle_gan_model.pth'):\n",
        "        \"\"\"\n",
        "        Save the current model state.\n",
        "\n",
        "        Args:\n",
        "        - path: Path to save the model. Default is 'cycle_gan_model.pth'.\n",
        "        \"\"\"\n",
        "        torch.save({\n",
        "            'gen_AtoB': self.gen_AtoB.state_dict(),\n",
        "            'gen_BtoA': self.gen_BtoA.state_dict(),\n",
        "            'dis_A': self.dis_A.state_dict(),\n",
        "            'dis_B': self.dis_B.state_dict(),\n",
        "            'optimizer_G': self.optimizer_G.state_dict(),\n",
        "            'optimizer_D_A': self.optimizer_D_A.state_dict(),\n",
        "            'optimizer_D_B': self.optimizer_D_B.state_dict(),\n",
        "        }, path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        \"\"\"\n",
        "        Load a saved model state.\n",
        "\n",
        "        Args:\n",
        "        - path: Path to the saved model.\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(path, weights_only=True)\n",
        "        self.gen_AtoB.load_state_dict(checkpoint['gen_AtoB'])\n",
        "        self.gen_BtoA.load_state_dict(checkpoint['gen_BtoA'])\n",
        "        self.dis_A.load_state_dict(checkpoint['dis_A'])\n",
        "        self.dis_B.load_state_dict(checkpoint['dis_B'])\n",
        "        self.optimizer_G.load_state_dict(checkpoint['optimizer_G'])\n",
        "        self.optimizer_D_A.load_state_dict(checkpoint['optimizer_D_A'])\n",
        "        self.optimizer_D_B.load_state_dict(checkpoint['optimizer_D_B'])\n",
        "\n",
        "    def generate_samples(self, real_A, real_B, n_images=4):\n",
        "        \"\"\"\n",
        "        Generate samples for with real, fake, reconstructed and identity images.\n",
        "        \"\"\"\n",
        "        real_A = real_A[:n_images]\n",
        "        real_B = real_B[:n_images]\n",
        "\n",
        "        fake_B, fake_A = self.forward(real_A, real_B)\n",
        "\n",
        "        self.eval()\n",
        "        recovered_B, recovered_A = self.forward(fake_A, fake_B)\n",
        "        id_B, id_A = self.forward(real_B, real_A) # pylint: disable=arguments-out-of-order\n",
        "\n",
        "        imgs_A = torch.vstack([real_A, fake_B, recovered_A, id_A])\n",
        "        imgs_B = torch.vstack([real_B, fake_A, recovered_B, id_B])\n",
        "\n",
        "        return imgs_A, imgs_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p77qc0A-A6b"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eNd_jm2PA5e"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "ydBBjjHjPA5f",
        "outputId": "6fcb3048-44d6-4cc6-9d62-99912714506a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241019_122559-a4trfhir</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabrielhafs-unicamp/cyclegan/runs/a4trfhir' target=\"_blank\">Test_2</a></strong> to <a href='https://wandb.ai/gabrielhafs-unicamp/cyclegan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabrielhafs-unicamp/cyclegan' target=\"_blank\">https://wandb.ai/gabrielhafs-unicamp/cyclegan</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabrielhafs-unicamp/cyclegan/runs/a4trfhir' target=\"_blank\">https://wandb.ai/gabrielhafs-unicamp/cyclegan/runs/a4trfhir</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gabrielhafs-unicamp/cyclegan/runs/a4trfhir?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a18c3ad2a10>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"cyclegan\",\n",
        "           name=\"Test_2\",\n",
        "           config=hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzzTQvq4PA5f"
      },
      "outputs": [],
      "source": [
        "def save_model(model, local_path='model.pth', wandb_log=True):\n",
        "    \"\"\"\n",
        "    Saves the model state to a local file and optionally logs it to Weights & Biases (WandB).\n",
        "\n",
        "    Saves a checkpoint of the model's state dictionary to the specified local file.\n",
        "    If `wandb_log` is True, the model will also be saved to WandB for remote logging.\n",
        "\n",
        "    Parameters:\n",
        "    ------------\n",
        "    model: torch.nn.Module\n",
        "        Model instance to save.\n",
        "    local_path: str\n",
        "        File path where the model will be saved locally.\n",
        "        (default: 'model.pth')\n",
        "    wandb_log: bool\n",
        "        Whether to log the model to WandB for version control\n",
        "        and experiment tracking.\n",
        "        (default: True)\n",
        "    \"\"\"\n",
        "    # Save locally\n",
        "    torch.save(model.state_dict(), local_path)\n",
        "\n",
        "    # Save to WandB\n",
        "    if wandb_log:\n",
        "        wandb.save(local_path)\n",
        "\n",
        "def save_losses(loss_G, loss_D_A, loss_D_B, loss_G_ad, loss_G_cycle, loss_G_id, filename='losses.txt'):\n",
        "    \"\"\"\n",
        "    Saves the generator and discriminator losses to a text file.\n",
        "\n",
        "    Saves a text file containing the losses for the generator and discriminators\n",
        "    (A and B) over the training epochs.\n",
        "\n",
        "    Args:\n",
        "    - loss_G (list): List of generator losses over the training epochs.\n",
        "    - loss_D_A (list): List of discriminator A losses over the training epochs.\n",
        "    - loss_D_B (list): List of discriminator B losses over the training epochs.\n",
        "    - filename (str): The file path where the losses will be saved. Defaults to 'losses.txt'.\n",
        "    \"\"\"\n",
        "    np.savetxt(\n",
        "        filename,\n",
        "        np.column_stack((loss_G, loss_D_A, loss_D_B, loss_G_ad, loss_G_cycle, loss_G_id)),\n",
        "        header='Generator total loss, Discriminator A loss, Discriminator B loss')\n",
        "\n",
        "def train_one_epoch(epoch, model, train_A, train_B, device, n_samples=None):\n",
        "    \"\"\"\n",
        "    Trains the CycleGAN model for a single epoch and returns the generator and discriminator losses.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current epoch number.\n",
        "    - model (CycleGAN): The CycleGAN model instance.\n",
        "    - train_A (DataLoader): DataLoader for domain A training images.\n",
        "    - train_B (DataLoader): DataLoader for domain B training images.\n",
        "    - device (torch.device): The device on which the model and data are\n",
        "    loaded (e.g., 'cuda' or 'cpu').\n",
        "    - n_samples (int): Number of samples to train on per batch.\n",
        "    If None, train on all samples. Default is None.\n",
        "\n",
        "    Returns:\n",
        "    - loss_G (float): The total loss of the generator for this epoch.\n",
        "    - loss_D_A (float): The total loss of discriminator A for this epoch.\n",
        "    - loss_D_B (float): The total loss of discriminator B for this epoch.\n",
        "\n",
        "    During training:\n",
        "    - It iterates through the batches of both domains (A and B) and performs\n",
        "    optimization on the generators and discriminators.\n",
        "    - Progress is tracked with a `tqdm` progress bar that shows current generator\n",
        "    and discriminator losses.\n",
        "    \"\"\"\n",
        "\n",
        "    progress_bar = tqdm(zip(train_A, train_B), desc=f'Epoch {epoch:03d}',\n",
        "                        leave=False, disable=False)\n",
        "\n",
        "    loss_G, loss_D_A, loss_D_B, loss_G_ad, loss_G_cycle, loss_G_id = 0, 0, 0, 0, 0, 0\n",
        "    for batch_A, batch_B in progress_bar:\n",
        "        progress_bar.set_description(f'Epoch {epoch:03d}')\n",
        "\n",
        "        if n_samples is not None:\n",
        "            batch_A = batch_A[:n_samples]\n",
        "            batch_B = batch_B[:n_samples]\n",
        "\n",
        "        real_A = batch_A.to(device)\n",
        "        real_B = batch_B.to(device)\n",
        "\n",
        "        # Perform one optimization step\n",
        "        loss = model.optimize(real_A, real_B)\n",
        "        loss_G += loss.loss_G.item()\n",
        "        loss_D_A += loss.loss_D_A.item()\n",
        "        loss_D_B += loss.loss_D_B.item()\n",
        "        loss_G_ad += loss.loss_G_ad.item()\n",
        "        loss_G_cycle += loss.loss_G_cycle.item()\n",
        "        loss_G_id += loss.loss_G_id.item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'G_loss': f'{loss.loss_G.item():.4f}',\n",
        "            'D_A_loss': f'{loss.loss_D_A.item():.4f}',\n",
        "            'D_B_loss': f'{loss.loss_D_B.item():.4f}'\n",
        "        })\n",
        "    progress_bar.close()\n",
        "\n",
        "    loss_G /= (len(train_A) + len(train_B)) / 2\n",
        "    loss_D_A /= len(train_A)\n",
        "    loss_D_B /= len(train_B)\n",
        "    loss_G_ad /= (len(train_A) + len(train_B)) / 2\n",
        "    loss_G_cycle /= (len(train_A) + len(train_B)) / 2\n",
        "    loss_G_id /= (len(train_A) + len(train_B)) / 2\n",
        "\n",
        "    msg = f'Epoch {epoch:03d}: G_loss={loss_G:.4f}, '\n",
        "    msg += f'D_A_loss={loss_D_A:.4f}, D_B_loss={loss_D_B:.4f}, '\n",
        "    msg += f'G_ad={loss_G_ad:.4f}, G_cycle={loss_G_cycle:.4f}, G_id={loss_G_id:.4f}'\n",
        "    print(msg)\n",
        "    return loss_G, loss_D_A, loss_D_B, loss_G_ad, loss_G_cycle, loss_G_id\n",
        "\n",
        "# Plot losses\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    \"\"\"\n",
        "    Plots the training and validation losses over the epochs.\n",
        "\n",
        "    Args:\n",
        "    - train_losses (list): List of training losses (e.g., generator losses) over the epochs.\n",
        "    - val_losses (list): List of validation losses over the epochs.\n",
        "\n",
        "    Displays:\n",
        "    - A line plot showing the progression of training and validation losses.\n",
        "    - Training and validation losses are plotted against the number of epochs.\n",
        "    \"\"\"\n",
        "    plt.plot(\n",
        "        range(1, len(train_losses) + 1),\n",
        "        train_losses,\n",
        "        label='Training Loss',\n",
        "        linewidth=2, alpha=0.7)\n",
        "    plt.plot(\n",
        "        range(1, len(val_losses) + 1),\n",
        "        val_losses,\n",
        "        label='Validation Loss',\n",
        "        linewidth=2, alpha=0.7)\n",
        "    plt.title('CycleGAN Training Losses')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLfKoOJQGOqQ"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfP1je__PA5f"
      },
      "source": [
        "The training loop includes the following steps:\n",
        "\n",
        "1. **Generate fake images** from the generators.\n",
        "2. **Compute adversarial loss** for both discriminators and generators.\n",
        "3. **Cycle loss** to ensure image reconstruction.\n",
        "4. **Identity loss** to preserve image identity during translation.\n",
        "5. Update the **discriminator and generator** weights using backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw9qxWKx-B-E"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "cycle_gan = CycleGAN(\n",
        "            input_nc=hyperparameters[\"channels\"],\n",
        "            output_nc=hyperparameters[\"channels\"],\n",
        "            device=hyperparameters[\"device\"],\n",
        "            n_features=hyperparameters[\"n_features\"],\n",
        "            n_residual_blocks=hyperparameters[\"n_residual_blocks\"],\n",
        "            n_downsampling=hyperparameters[\"n_downsampling\"],\n",
        "            cycle_loss_weight=hyperparameters[\"cycle_loss_weight\"],\n",
        "            id_loss_weight=hyperparameters[\"id_loss_weight\"],\n",
        "            lr=hyperparameters[\"lr\"],\n",
        "            beta1=hyperparameters[\"beta1\"],\n",
        "            beta2=hyperparameters[\"beta2\"],\n",
        "        )\n",
        "\n",
        "train_losses_G, train_losses_D_A, train_losses_D_B = [], [], []\n",
        "train_losses_G_ad, train_losses_G_cycle, train_losses_G_id = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z48HS8KmPA5g"
      },
      "outputs": [],
      "source": [
        "from drive.MyDrive.CycleGAN.src.utils import show_img\n",
        "\n",
        "out_folder = Path().resolve() / 'no_sync/test_model'\n",
        "out_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for epoch in range(hyperparameters[\"num_epochs\"]):\n",
        "    loss_G, loss_D_A, loss_D_B, loss_G_ad, loss_G_cycle, loss_G_id = train_one_epoch(\n",
        "        epoch=epoch,\n",
        "        model=cycle_gan,\n",
        "        train_A=train_A,\n",
        "        train_B=train_B,\n",
        "        device=hyperparameters[\"device\"],\n",
        "        n_samples=None)\n",
        "\n",
        "    train_losses_G.append(loss_G)\n",
        "    train_losses_D_A.append(loss_D_A)\n",
        "    train_losses_D_B.append(loss_D_B)\n",
        "    train_losses_G_ad.append(loss_G_ad)\n",
        "    train_losses_G_cycle.append(loss_G_cycle)\n",
        "    train_losses_G_id.append(loss_G_id)\n",
        "\n",
        "    # Save the average losses to a file\n",
        "    save_losses(\n",
        "        train_losses_G, train_losses_D_A, train_losses_D_B,\n",
        "        train_losses_G_ad, train_losses_G_cycle, train_losses_G_id,\n",
        "        filename=out_folder / 'train_losses.txt')\n",
        "\n",
        "    if epoch % hyperparameters[\"checkpoint_interval\"] == 0:\n",
        "        save_model(cycle_gan, local_path=f'cycle_gan_epoch_{epoch}.pth', wandb_log=True)\n",
        "\n",
        "    wandb.log({\n",
        "            'G_loss/train': loss_G,\n",
        "            'D_A_loss/train': loss_D_A,\n",
        "            'D_B_loss/train': loss_D_B,\n",
        "            'G_loss_ad/train': loss_G_ad,\n",
        "            'G_loss_cycle/train': loss_G_cycle,\n",
        "            'G_loss_id/train': loss_G_id,\n",
        "    })\n",
        "\n",
        "    real_A = next(iter(test_A))\n",
        "    real_B = next(iter(test_B))\n",
        "\n",
        "    n_images = 4\n",
        "\n",
        "    real_A = real_A.cuda()\n",
        "    real_B = real_B.cuda()\n",
        "\n",
        "    imgs_A, imgs_B = cycle_gan.generate_samples(real_A, real_B, n_images=n_images)\n",
        "\n",
        "    show_img(imgs_A, title=f'Epoch {epoch} - A Images',\n",
        "              figsize = (20, 16), change_scale=True, nrow=n_images,\n",
        "              labels=['Real', 'Fake', 'Recovered', 'Identity'])\n",
        "    plt.savefig(out_folder / f'imgs_{epoch}_A.png')\n",
        "\n",
        "    show_img(imgs_B, title=f'Epoch {epoch} - B Images',\n",
        "              figsize = (20, 16), change_scale=True, nrow=n_images,\n",
        "              labels=['Real', 'Fake', 'Recovered', 'Identity'])\n",
        "    plt.savefig(out_folder / f'imgs_{epoch}_B.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbwwZuAWPA5g"
      },
      "source": [
        "## Verifying the losses"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}